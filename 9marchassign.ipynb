{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7fe2eae-ffe8-4ae2-ab20-a698ba406d83",
   "metadata": {},
   "source": [
    "# **ASSIGNMENT**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a16533a-de41-4a26-952a-1fba3ef58aec",
   "metadata": {},
   "source": [
    "**Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with an example.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d15251b-36ef-4a3a-8a79-428e211c2d46",
   "metadata": {},
   "source": [
    "Probability Mass Function (PMF) and Probability Density Function (PDF) are both mathematical functions used to describe the probability distribution of a random variable.\n",
    "\n",
    "1. Probability Mass Function (PMF):\n",
    "The PMF is used for discrete random variables. It gives the probability of each possible outcome in a discrete set of values. The PMF is defined as:\n",
    "\n",
    "PMF(x) = P(X = x)\n",
    "\n",
    "where X is the random variable and x is a specific value of X. The PMF assigns a probability to each value of the random variable.\n",
    "\n",
    "Example: Consider rolling a fair six-sided die. The random variable X represents the outcome of the roll. The PMF for X is given by:\n",
    "\n",
    "PMF(x) = 1/6, for x = 1, 2, 3, 4, 5, 6\n",
    "PMF(x) = 0,   otherwise\n",
    "\n",
    "This means that the probability of rolling a 1, 2, 3, 4, 5, or 6 is 1/6 each, and the probability of any other value is 0.\n",
    "\n",
    "2. Probability Density Function (PDF):\n",
    "The PDF is used for continuous random variables. It represents the density of probability over a continuous range of values. Unlike the PMF, which assigns probabilities to specific values, the PDF gives the relative likelihood of the random variable taking on a particular value within a range. The PDF is defined such that the probability of the random variable falling within a specific interval is given by the integral of the PDF over that interval.\n",
    "\n",
    "Example: Let's consider a continuous random variable X that follows a standard normal distribution with mean 0 and standard deviation 1. The PDF for X is given by:\n",
    "\n",
    "PDF(x) = (1 / √(2π)) * e^((-x^2)/2)\n",
    "\n",
    "The PDF represents the shape of the bell curve associated with the normal distribution. The height of the curve at any given point represents the relative likelihood of the random variable taking on that value.\n",
    "\n",
    "It's important to highlight that the sum of probabilities over all possible values for the PMF is equal to 1, whereas the integral of the PDF over its entire range is equal to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56e1d51-1051-4843-8a77-8e9e6d125436",
   "metadata": {},
   "source": [
    "**Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f84149-3215-4991-abe1-2fa8c313de3e",
   "metadata": {},
   "source": [
    "The Cumulative Distribution Function (CDF) is a mathematical function that provides the probability that a random variable takes on a value less than or equal to a given value. It gives us cumulative information about the distribution of a random variable.\n",
    "\n",
    "For a random variable X, the CDF is defined as:\n",
    "\n",
    "CDF(x) = P(X ≤ x)\n",
    "\n",
    "The CDF provides the cumulative probabilities for different values of x, starting from negative infinity up to x.\n",
    "\n",
    "Example: Let's consider a continuous random variable X that follows a standard normal distribution with mean 0 and standard deviation 1. The CDF for X, denoted as Φ(x), can be calculated using the standard normal distribution table or a mathematical function. For instance, Φ(0) represents the probability that X is less than or equal to 0.\n",
    "\n",
    "The CDF is used to answer questions like \"What is the probability that X is less than or equal to 2?\" or \"What is the probability that X is greater than -1?\" by evaluating the CDF at the specific value or range of values of interest. It provides a cumulative perspective on the probabilities associated with a random variable.\n",
    "\n",
    "The CDF is widely used in statistical analysis and probability theory for various purposes:\n",
    "\n",
    "1. Probability calculations: The CDF allows us to determine the probability of a random variable falling within a certain range or being less than or equal to a specific value.\n",
    "\n",
    "2. Quantile calculations: The CDF enables us to find the value(s) of a random variable that correspond to a given probability. This is useful for determining percentiles or confidence intervals.\n",
    "\n",
    "3. Distribution comparisons: The CDF can be used to compare different distributions and assess their similarities or differences.\n",
    "\n",
    "4. Random number generation: The CDF can be inverted to generate random numbers from a specific probability distribution.\n",
    "\n",
    "Overall, the CDF provides valuable information about the cumulative probabilities associated with a random variable, allowing for various statistical calculations and analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a7087a-2385-4397-b528-87f73cff397c",
   "metadata": {},
   "source": [
    "**Q3: What are some examples of situations where the normal distribution might be used as a model? Explain how the parameters of the normal distribution relate to the shape of the distribution.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83f2b28-b2e6-4a76-90ee-e61a9a3c208a",
   "metadata": {},
   "source": [
    "The normal distribution, also known as the Gaussian distribution or bell curve, is widely used as a model in various fields due to its versatility and applicability to many real-world situations. Here are some examples of situations where the normal distribution might be used as a model:\n",
    "\n",
    "1. Heights and weights: The distribution of heights and weights in a population often follows a normal distribution. The mean and standard deviation of the normal distribution can provide insights into the average height or weight and the spread of values around the mean.\n",
    "\n",
    "2. IQ scores: Intelligence quotient (IQ) scores are often assumed to follow a normal distribution. The mean and standard deviation of the normal distribution can help understand the average intelligence level and the variability of IQ scores in a population.\n",
    "\n",
    "3. Measurement errors: In many scientific and engineering measurements, there is a certain degree of measurement error present. Assuming that these errors are normally distributed allows for the use of statistical techniques that rely on the normal distribution, such as hypothesis testing or confidence intervals.\n",
    "\n",
    "4. Financial markets: In finance, the normal distribution is commonly used to model the returns of stocks or other financial instruments. This assumption is made in many models, including the famous Black-Scholes option pricing model. The mean and standard deviation of the normal distribution can provide insights into the average return and the volatility of an asset.\n",
    "\n",
    "The shape of the normal distribution is determined by two parameters: the mean (μ) and the standard deviation (σ). Here's how these parameters relate to the shape of the distribution:\n",
    "\n",
    "1. Mean (μ): The mean determines the center or location of the normal distribution. It represents the average value around which the data is symmetrically distributed. The mean is also the peak of the bell curve. Shifting the mean to the left or right changes the center of the distribution without affecting its shape.\n",
    "\n",
    "2. Standard deviation (σ): The standard deviation controls the spread or variability of the distribution. A smaller standard deviation results in a narrower and taller curve, indicating less dispersion of values around the mean. Conversely, a larger standard deviation leads to a wider and flatter curve, indicating greater dispersion.\n",
    "\n",
    "Therefore, the normal distribution is commonly used in situations where data tends to cluster around a central value with decreasing likelihood as values move away from the center. The mean determines the center of the distribution, and the standard deviation determines the spread or variability of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b971e10-7b6d-459f-9b3b-aca870e90b02",
   "metadata": {},
   "source": [
    "**Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal Distribution.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcde0a51-053a-43b3-91b7-80bea5aede54",
   "metadata": {},
   "source": [
    "The normal distribution is of great importance in statistics and data analysis due to its numerous properties and wide applicability. Here are some key reasons why the normal distribution is important:\n",
    "\n",
    "Central Limit Theorem: The normal distribution plays a fundamental role in the Central Limit Theorem, which states that the distribution of the sum or average of a large number of independent and identically distributed random variables tends to be approximately normal, regardless of the shape of the original distribution. This theorem is crucial in many statistical inference methods, allowing us to make reliable conclusions about populations based on sample data.\n",
    "\n",
    "Statistical inference: Many statistical methods and tests, such as hypothesis testing and confidence intervals, rely on the assumption of normality. By assuming that data follows a normal distribution, we can apply these methods to make valid inferences about population parameters.\n",
    "\n",
    "Parameter estimation: In various statistical models, the assumption of normality simplifies parameter estimation. Maximum likelihood estimation (MLE) and least squares estimation are commonly used techniques that rely on the assumption of normally distributed errors or residuals.\n",
    "\n",
    "Data transformations: The normal distribution provides a baseline for data transformation. In cases where the data does not follow a normal distribution, applying appropriate transformations (such as logarithmic or power transformations) can help achieve normality and improve the validity of statistical analyses.\n",
    "\n",
    "Real-life examples of phenomena that often follow a normal distribution include:\n",
    "\n",
    "Human characteristics: Heights, weights, IQ scores, blood pressure readings, and other physical or psychological traits of human populations often approximate a normal distribution.\n",
    "\n",
    "Test scores: In standardized tests like the SAT or IQ tests, scores are often assumed to be normally distributed. This assumption helps determine percentiles and set cutoff scores for different performance categories.\n",
    "\n",
    "Errors in measurements: Measurement errors in various scientific experiments, such as laboratory measurements or instrument readings, are often modeled as normally distributed. This assumption allows for the use of statistical techniques to quantify and analyze measurement uncertainty.\n",
    "\n",
    "Stock market returns: Daily or monthly returns of stocks or other financial instruments are commonly assumed to follow a normal distribution (or a closely related distribution, such as the log-normal distribution). This assumption is used in various financial models and risk management practices.\n",
    "\n",
    "These examples highlight the prevalence of the normal distribution in many areas of study and its usefulness in statistical analysis and modeling.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85506a5b-c8d3-4402-be23-9abe0561d991",
   "metadata": {},
   "source": [
    "**Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli\n",
    "Distribution and Binomial Distribution?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1112e893-bbcf-49a1-83bc-d34d6028f129",
   "metadata": {},
   "source": [
    "The Bernoulli distribution is a discrete probability distribution that models a single binary outcome, which can take one of two possible values, typically labeled as \"success\" (usually denoted as 1) or \"failure\" (usually denoted as 0). The distribution is characterized by a single parameter, usually denoted as p, which represents the probability of success.\n",
    "\n",
    "The probability mass function (PMF) of the Bernoulli distribution is given by:\n",
    "\n",
    "P(X = k) = p^k * (1-p)^(1-k)\n",
    "\n",
    "where X is the random variable representing the outcome, k is the value (0 or 1) that X can take, and p is the probability of success.\n",
    "\n",
    "Example: Let's consider flipping a fair coin. If we define a success as getting heads (H), and failure as getting tails (T), then the outcome of a single coin flip can be modeled using the Bernoulli distribution. The probability of success (getting heads) is 0.5, and the probability of failure (getting tails) is also 0.5. Thus, the PMF of the Bernoulli distribution for this example is:\n",
    "\n",
    "P(X = 1) = 0.5\n",
    "P(X = 0) = 0.5\n",
    "\n",
    "The Bernoulli distribution is a special case of the binomial distribution, which is a discrete probability distribution that models the number of successes in a fixed number of independent Bernoulli trials.\n",
    "\n",
    "The key difference between the Bernoulli distribution and the binomial distribution lies in the number of trials. In the Bernoulli distribution, there is only one trial, whereas the binomial distribution involves multiple trials.\n",
    "\n",
    "The binomial distribution is characterized by two parameters: n (the number of trials) and p (the probability of success in each trial). The binomial distribution describes the probability of obtaining exactly k successes in n independent Bernoulli trials.\n",
    "\n",
    "The probability mass function (PMF) of the binomial distribution is given by:\n",
    "\n",
    "P(X = k) = C(n, k) * p^k * (1-p)^(n-k)\n",
    "\n",
    "where X is the random variable representing the number of successes, k is the number of successes, n is the number of trials, p is the probability of success in each trial, and C(n, k) represents the number of ways to choose k successes out of n trials (binomial coefficient).\n",
    "\n",
    "Therefore, the Bernoulli distribution models a single binary outcome, while the binomial distribution models the number of successes in a fixed number of independent Bernoulli trials. The Bernoulli distribution can be seen as a special case of the binomial distribution with n = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2d20fe-0b51-4beb-8c0f-cafdca2d6dae",
   "metadata": {},
   "source": [
    "**Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset\n",
    "is normally distributed, what is the probability that a randomly selected observation will be greater\n",
    "than 60? Use the appropriate formula and show your calculations.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb5b600-86b7-429c-a4dc-7e0f90a8ad3c",
   "metadata": {},
   "source": [
    "Calculation by python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b266433-0839-432b-a4df-5c02b022640f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics,scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63f42837-0b3d-4b40-a92c-81395a1b3f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8413447460685429"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.norm.cdf(60,50,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17ab8d15-ede4-4962-8f8a-cd0fe1177d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob=1-scipy.stats.norm.cdf(60,50,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80d068f8-74fe-42fd-8451-7ce51e2b0837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability that a randomly selected observation will be greater than 60: 15.865525393145708\n"
     ]
    }
   ],
   "source": [
    "print(\"Probability that a randomly selected observation will be greater than 60:\",prob*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b92702f-2686-4e35-84d7-aaf7827cedef",
   "metadata": {},
   "source": [
    "Calculation by hand:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6f4b78-c012-4c44-92aa-0023981fa525",
   "metadata": {},
   "source": [
    "Given: μ=50<br>\n",
    "       σ=10<br>\n",
    "       x=60<br>\n",
    "       P(X > x) = 1 - P(X ≤ x) = 1 - CDF(x; μ, σ)<br>\n",
    "       \n",
    "Firstly, we will find CDF(x; μ, σ):<br>       \n",
    "       \n",
    "If we are given the mean (μ),standard deviation (σ), and a specific value (x) then to calculate the CDF in this scenario:\n",
    "\n",
    "1. Standardize the value x: Subtract the mean (μ) from x and divide the result by the standard deviation (σ).\n",
    "\n",
    "   z = (x - μ) / σ\n",
    "\n",
    "3. Use the standardized value z to look up the corresponding cumulative probability in a standard normal distribution table or use a statistical software function that provides the CDF of a standard normal distribution (e.g., the erf or norm.cdf function in Python).\n",
    "\n",
    "   F(z) = P(Z ≤ z)\n",
    "\n",
    "   Here, Z represents a standard normal random variable.\n",
    "\n",
    "4. The calculated value F(z) represents the probability that a standard normal random variable is less than or equal to z, which is equivalent to the probability that the original random variable X is less than or equal to x.       \n",
    "       \n",
    "       \n",
    "\n",
    "z = (x - μ) / σ\n",
    "          =(60-50)/10\n",
    "          =1<br>\n",
    "          \n",
    "Then, F(z) = P(Z ≤ z) \n",
    "         = 0.8413<br>\n",
    "           \n",
    "Thus, P(X <= x) =F(z) <br> \n",
    "Therefore, P(X <= x)=0.8413<br>\n",
    "\n",
    "Hence, P(X > x) = 1 - P(X ≤ x) = 1 - CDF(x; μ, σ)\n",
    "                = 1-0.8413\n",
    "                = 0.15865<br>\n",
    "                \n",
    "Probability that a randomly selected observation will be greater than 60 is **15.865**             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5f3c4c-eace-45d7-9d2b-490477b228ba",
   "metadata": {},
   "source": [
    "**Q7: Explain uniform Distribution with an example.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4414ea04-7a45-4af3-86fc-b7c442a6cf29",
   "metadata": {},
   "source": [
    "The uniform distribution is a probability distribution that describes a situation where all outcomes within a given range are equally likely. It is characterized by a constant probability density function (PDF) over the range of possible values.\n",
    "\n",
    "In the uniform distribution, every possible outcome has the same probability of occurring. This distribution is often visualized as a rectangular shape, where the height of the rectangle represents the constant probability.\n",
    "\n",
    "Example: Let's consider rolling a fair six-sided die. The outcomes of rolling the die are integers from 1 to 6. If each face of the die is equally likely, we can model the outcome as a uniform distribution.\n",
    "\n",
    "In this case, the probability of getting any specific face (1, 2, 3, 4, 5, or 6) is 1/6, as each face is equally likely. The uniform distribution for this example can be represented by the following probability density function (PDF):\n",
    "\n",
    "f(x) = 1/6, for x ∈ {1, 2, 3, 4, 5, 6}\n",
    "f(x) = 0, otherwise\n",
    "\n",
    "This means that any value outside the range of 1 to 6 will have a probability of 0, while the probability of getting any specific value within that range is 1/6.\n",
    "\n",
    "The uniform distribution is not limited to discrete outcomes like rolling a die. It can also apply to continuous outcomes. For example, if you randomly select a number between 0 and 1 with equal probability, that would follow a continuous uniform distribution over the interval [0, 1].\n",
    "\n",
    "The uniform distribution is used in various applications, such as random number generation, simulations, and when assuming equal likelihood for certain events or measurements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af954f50-54b5-4968-8ed0-d4874ca1fcb3",
   "metadata": {},
   "source": [
    "**Q8: What is the z score? State the importance of the z score.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eef1368-3fc5-46aa-9d19-8b79fd8b6b9d",
   "metadata": {},
   "source": [
    "The z-score, also known as the standard score, is a statistical measure that quantifies how many standard deviations a data point is away from the mean of a distribution. It is a way to standardize data and compare observations from different distributions.\n",
    "\n",
    "The formula to calculate the z-score for a data point x, given the mean (μ) and standard deviation (σ) of the distribution, is:\n",
    "\n",
    "z = (x - μ) / σ\n",
    "\n",
    "The z-score tells us how many standard deviations a data point is above or below the mean. A positive z-score indicates that the data point is above the mean, while a negative z-score indicates it is below the mean. A z-score of 0 means the data point is exactly at the mean.\n",
    "\n",
    "Importance of the z-score:\n",
    "\n",
    "1. Standardization and Comparison: The z-score allows for the standardization of different variables or data sets, making it easier to compare observations from different distributions. It provides a common scale to assess the relative position of a data point within its distribution.\n",
    "\n",
    "2. Identifying Outliers: The z-score helps identify outliers by quantifying how extreme or unusual a data point is relative to the rest of the distribution. Data points with z-scores significantly above or below a certain threshold (e.g., ±2 or ±3) are considered outliers.\n",
    "\n",
    "3. Probability Calculation: The z-score is used to calculate probabilities associated with a normal distribution. By converting a value to its corresponding z-score, we can determine the probability of obtaining a value less than, greater than, or between certain values.\n",
    "\n",
    "4. Hypothesis Testing: The z-score is essential in hypothesis testing and constructing confidence intervals. It allows researchers to determine whether an observed difference or effect is statistically significant by comparing the z-score to critical values from the standard normal distribution.\n",
    "\n",
    "5. Data Transformation: The z-score transformation is often employed to normalize skewed or non-normally distributed data. By converting data to z-scores, skewed distributions can be made closer to a standard normal distribution, which can be useful for certain statistical analyses.\n",
    "\n",
    "Overall, the z-score is a fundamental statistical tool that provides a standardized measure of a data point's deviation from the mean. It enables comparison, identification of outliers, probability calculations, hypothesis testing, and data transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e71b39d-7443-412c-8957-a3f1ad0aa267",
   "metadata": {},
   "source": [
    "**Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acab226b-bdf7-4ea4-b1cd-62387cbdff02",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) is a fundamental concept in statistics that states that the sampling distribution of the mean of a sufficiently large number of independent and identically distributed (i.i.d.) random variables will be approximately normally distributed, regardless of the shape of the original population distribution.\n",
    "\n",
    "In simpler terms, the Central Limit Theorem states that if you take many random samples from any population, the distribution of the sample means will be approximately normal, regardless of the shape of the population distribution.\n",
    "\n",
    "Significance of the Central Limit Theorem:\n",
    "\n",
    "1. Normal Approximation: The Central Limit Theorem allows us to approximate the distribution of sample means, regardless of the shape of the population distribution. This approximation is particularly useful when the population distribution is not known or is non-normal.\n",
    "\n",
    "2. Inference and Confidence Intervals: The CLT is the foundation of statistical inference and hypothesis testing. It enables the use of parametric tests, such as the t-test or z-test, which rely on the assumption of normality. It also helps in constructing confidence intervals for population parameters, such as the mean.\n",
    "\n",
    "3. Sample Size Determination: The CLT helps determine the appropriate sample size required for statistical inference. By knowing the desired level of precision and the variability of the population, we can estimate the sample size needed to achieve a desired level of confidence in our results.\n",
    "\n",
    "4. Real-World Applications: The Central Limit Theorem is applicable in various fields and practical scenarios. It allows us to make inferences about large populations using samples, even when the population distribution is unknown or non-normal. This is particularly useful in market research, quality control, opinion polling, and many other areas where sampling and generalization are crucial.\n",
    "\n",
    "5. Basis for Normality Assumption: Many statistical techniques, such as linear regression and analysis of variance (ANOVA), assume that the data are normally distributed. The Central Limit Theorem provides a justification for these assumptions, as the means of samples tend to follow a normal distribution.\n",
    "\n",
    "Therefore, the Central Limit Theorem is significant because it enables us to make reliable statistical inferences, perform hypothesis testing, estimate confidence intervals, and apply various statistical techniques even when the population distribution is unknown or non-normal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146ac75e-49b1-4383-943f-82c28cb8bc32",
   "metadata": {},
   "source": [
    "**Q10: State the assumptions of the Central Limit Theorem.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aa83e0-14fd-4b6b-85ee-3119386ef348",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) relies on certain assumptions to hold true. These assumptions are as follows:\n",
    "\n",
    "1. Independence: The random variables in the sample should be independent of each other. This means that the value of one random variable should not be influenced by or dependent on the values of other random variables in the sample.\n",
    "\n",
    "2. Identical Distribution: The random variables in the sample should be identically distributed. This means that they should follow the same probability distribution, with the same mean and variance.\n",
    "\n",
    "3. Finite Variance: The random variables in the population should have a finite variance. This ensures that the sample means are well-behaved and do not have extreme or infinite values.\n",
    "\n",
    "4. Sufficient Sample Size: The Central Limit Theorem becomes more applicable and accurate as the sample size increases. Although there is no specific threshold, a commonly used guideline is that the sample size should be at least 30. However, the CLT can still provide reasonable approximations for moderately sized samples, especially when the underlying population distribution is not heavily skewed or has outliers.\n",
    "\n",
    "It is important to note that violating these assumptions may affect the applicability and accuracy of the Central Limit Theorem. If the assumptions are not met, alternative statistical techniques or modifications to the CLT may be required to make valid inferences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8b8857-5f24-49ce-8a50-931b08a45fcf",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30a8945-ccd2-43d2-b40e-db3a658b5825",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
